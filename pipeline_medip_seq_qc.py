##############################################################################
#
#   MRC FGU CGAT
#
#   $Id$
#
#   Copyright (C) 2017 Tom Smith
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
###############################################################################
"""===========================
Pipeline MeDIP-Seq BAM stats
===========================

:Author: Tom Smith
:Release: $Id$
:Date: |today|
:Tags: Python

Overview
========

This pipeline performs BAM QC on 'raw' MeDIP BAMS from Ion Torrent.

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.
CGATReport report requires a :file:`conf.py`.

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_medip_seq_qc.py config

Input files
-----------

None required except the pipeline configuration files.

Requirements
------------

The pipeline requires the results from
:doc:`pipeline_annotations`. Set the configuration variable
:py:data:`annotations_database` and :py:data:`annotations_dir`.

On top of the default CGAT setup, the pipeline requires the following
software to be in the path:

.. Add any additional external requirements such as 3rd party software
   or R modules below:

Requirements:

* samtools >= 1.1
* picard

Glossary
========

.. glossary::


Code
====

"""
from ruffus import *

import sys
import os
import sqlite3

import CGAT.Experiment as E
import CGATPipelines.Pipeline as P

import CGATPipelines.PipelineMappingQC as PipelineMappingQC
import CGATPipelines.PipelineWindows as PipelineWindows

# load options from the config file
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])

# add configuration values from associated pipelines
#
# 1. pipeline_annotations: any parameters will be added with the
#    prefix "annotations_". The interface will be updated with
#    "annotations_dir" to point to the absolute path names.
PARAMS.update(P.peekParameters(
    PARAMS["annotations_dir"],
    "pipeline_annotations.py",
    on_error_raise=__name__ == "__main__",
    prefix="annotations_",
    update_interface=True))


# if necessary, update the PARAMS dictionary in any modules file.
# e.g.:
#
# import CGATPipelines.PipelineGeneset as PipelineGeneset
# PipelineGeneset.PARAMS = PARAMS
#
# Note that this is a hack and deprecated, better pass all
# parameters that are needed by a function explicitely.

# -----------------------------------------------
# Utility functions
def connect():
    '''utility function to connect to database.

    Use this method to connect to the pipeline database.
    Additional databases can be attached here as well.

    Returns an sqlite3 database handle.
    '''

    dbh = sqlite3.connect(PARAMS["database_name"])
    statement = '''ATTACH DATABASE '%s' as annotations''' % (
        PARAMS["annotations_database"])
    cc = dbh.cursor()
    cc.execute(statement)
    cc.close()

    return dbh

BAMFILES = "./*bam"

@follows(mkdir("cleaned_bams.dir"))
@transform(BAMFILES,
           regex("./(\S+).bam"),
           r"cleaned_bams.dir/\1.bam")
def cleanBams(infile, outfile):
    '''Remove any alignment to "random" and "Un" contigs.'''
    samout = outfile.replace(".bam", ".sam")

    statement = '''
    samtools view -H %(infile)s >  %(samout)s;
    samtools view %(infile)s| awk '$3~/^chr[[:alnum:]{1-2}]$/'  >> %(samout)s;
    samtools view -b %(samout)s > %(outfile)s;
    samtools index %(outfile)s;
    rm -f %(samout)s
    '''

    P.run()

################################################################################
################################################################################
## QC on whole BAM
################################################################################
################################################################################

@follows(mkdir("nreads.dir"))
@transform(cleanBams,
           regex("cleaned_bams.dir/(\S+).bam"),
           r"nreads.dir/\1.nreads")
def countReads(infile, outfile):
    '''Count number of reads in input files.'''

    statement = '''
    echo -n nreads_ > %(outfile)s;
    samtools view -c %(infile)s >> %(outfile)s;
    sed -i 's/_/\\t/'g %(outfile)s;'''

    P.run()


@P.add_doc(PipelineMappingQC.buildPicardAlignmentStats)
@mkdir("picard")
@transform(cleanBams,
           regex("cleaned_bams.dir/(\S+).bam"),
           add_inputs(os.path.join(PARAMS["genome_dir"],
                                   PARAMS["genome"] + ".fa")),
           r"picard/\1.picard_stats")
def buildPicardStats(infiles, outfile):
    ''' build Picard alignment stats '''
    infile, reffile = infiles

    PipelineMappingQC.buildPicardAlignmentStats(
        infile, outfile, reffile)

@P.add_doc(PipelineMappingQC.loadPicardAlignmentStats)
@jobs_limit(PARAMS.get("jobs_limit_db", 1), "db")
@merge(buildPicardStats, "picard_stats.load")
def loadPicardStats(infiles, outfile):
    '''merge alignment stats into single tables.'''
    PipelineMappingQC.loadPicardAlignmentStats(infiles, outfile)


@P.add_doc(PipelineMappingQC.buildPicardDuplicationStats)
@mkdir("picard")
@transform(cleanBams,
           regex("cleaned_bams.dir/(\S+).bam"),
           r"picard/\1.picard_duplication_metrics")
def buildPicardDuplicationStats(infile, outfile):
    '''Get duplicate stats from picard MarkDuplicates '''
    PipelineMappingQC.buildPicardDuplicationStats(infile, outfile)


@P.add_doc(PipelineMappingQC.loadPicardDuplicationStats)
@jobs_limit(PARAMS.get("jobs_limit_db", 1), "db")
@merge(buildPicardDuplicationStats, ["picard_duplication_stats.load",
                                     "picard_duplication_histogram.load"])
def loadPicardDuplicationStats(infiles, outfiles):
    '''merge alignment stats into single tables.'''
    # separate load function while testing
    PipelineMappingQC.loadPicardDuplicationStats(infiles, outfiles)


@follows(countReads)
@mkdir("bam_stats.dir")
@transform(cleanBams,
           regex("cleaned_bams.dir/(\S+).bam"),
           add_inputs(r"nreads.dir/\1.nreads"),
           r"bam_stats.dir/\1.readstats")
def buildBAMStats(infiles, outfile):
    '''count number of reads mapped, duplicates, etc.

    Excludes regions overlapping repetitive RNA sequences

    Parameters
    ----------
    infiles : lists
    infiles[0] : str
       Input filename in :term:`bam` format
    infiles[1] : str
       Input filename with number of reads per sample

    outfile : str
       Output filename with read stats

    annotations_interface_rna_gtf : str
        :term:`PARMS`. :term:`gtf` format file with repetitive rna
    '''

    rna_file = PARAMS["annotations_interface_rna_gff"]

    job_memory = "32G"

    bamfile, readsfile = infiles

    nreads = PipelineMappingQC.getNumReadsFromReadsFile(readsfile)
    track = P.snip(os.path.basename(readsfile),
                   ".nreads")

    # if a fastq file exists, submit for counting
    if os.path.exists(track + ".fastq.gz"):
        fastqfile = track + ".fastq.gz"
    elif os.path.exists(track + ".fastq.1.gz"):
        fastqfile = track + ".fastq.1.gz"
    else:
        fastqfile = None

    if fastqfile is not None:
        fastq_option = "--fastq-file=%s" % fastqfile
    else:
        fastq_option = ""

    statement = '''
    cgat bam2stats
         %(fastq_option)s
         --force-output
         --mask-bed-file=%(rna_file)s
         --ignore-masked-reads
         --num-reads=%(nreads)i
         --output-filename-pattern=%(outfile)s.%%s
    < %(bamfile)s
    > %(outfile)s
    '''

    P.run()


@P.add_doc(PipelineMappingQC.loadBAMStats)
@jobs_limit(PARAMS.get("jobs_limit_db", 1), "db")
@merge(buildBAMStats, "bam_stats.load")
def loadBAMStats(infiles, outfile):
    ''' load bam statistics into bam_stats table '''
    PipelineMappingQC.loadBAMStats(infiles, outfile)


@P.add_doc(PipelineWindows.summarizeTagsWithinContext)
@mkdir("bam_stats.dir")
@transform(cleanBams,
           regex("cleaned_bams.dir/(\S+).bam"),
           add_inputs(
               PARAMS["annotations_interface_genomic_context_bed"]),
           r"bam_stats.dir/\1.contextstats.tsv.gz")
def buildContextStats(infiles, outfile):
    ''' build mapping context stats '''
    PipelineWindows.summarizeTagsWithinContext(
        infiles[0], infiles[1], outfile)


@P.add_doc(PipelineWindows.loadSummarizedContextStats)
@jobs_limit(PARAMS.get("jobs_limit_db", 1), "db")
@follows(loadBAMStats)
@merge(buildContextStats, "context_stats.load")
def loadContextStats(infiles, outfile):
    ''' load context mapping statistics into context_stats table '''
    PipelineWindows.loadSummarizedContextStats(infiles, outfile)


@follows(loadPicardStats,
         loadPicardDuplicationStats,
         loadBAMStats,
         loadContextStats)
def runBasicBAMQC():
    pass

# ---------------------------------------------------
# Generic pipeline tasks
#@follows(loadWordCounts)
#def full():
#    pass


@follows(mkdir("report"))
def build_report():
    '''build report from scratch.

    Any existing report will be overwritten.
    '''

    E.info("starting report build process from scratch")
    P.run_report(clean=True)


@follows(mkdir("report"))
def update_report():
    '''update report.

    This will update a report with any changes inside the report
    document or code. Note that updates to the data will not cause
    relevant sections to be updated. Use the cgatreport-clean utility
    first.
    '''

    E.info("updating report")
    P.run_report(clean=False)


@follows(update_report)
def publish_report():
    '''publish report in the CGAT downloads directory.'''

    E.info("publishing report")
    P.publish_report()

if __name__ == "__main__":
    sys.exit(P.main(sys.argv))
